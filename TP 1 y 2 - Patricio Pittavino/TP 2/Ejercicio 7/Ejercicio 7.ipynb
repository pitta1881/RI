{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by pitta on 2024-04-03 16:14) and terrier-helper 0.0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../../shared\"))  # Agrega la carpeta al PYTHONPATH\n",
    "from tokenizer_v2 import tokenizer, loadFileStopWords\n",
    "from collections import Counter\n",
    "import math\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import pyterrier as pt\n",
    "\n",
    "if not pt.started():\n",
    "  pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio donde se encuentran los documentos de texto\n",
    "DIR = '../wiki-small'\n",
    "STOP_WORDS_FILE = '../../shared/stop-words.en.txt'\n",
    "stop_words_list = loadFileStopWords(STOP_WORDS_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:33:46.479 [main] ERROR org.terrier.structures.indexing.Indexer - Could not rename index\n",
      "java.io.IOException: Rename of index structure file 'f:\\UNLu\\Recuperacion de la Informacion\\TPs code\\TP2\\Ejercicio 7\\custom_index/data_1.direct.bf' (exists) to 'f:\\UNLu\\Recuperacion de la Informacion\\TPs code\\TP2\\Ejercicio 7\\custom_index/data.direct.bf' (exists) failed - likely that source file is still open. Possible indexing bug?\n",
      "\tat org.terrier.structures.IndexUtil.renameIndex(IndexUtil.java:379)\n",
      "\tat org.terrier.structures.indexing.Indexer.index(Indexer.java:388)\n"
     ]
    }
   ],
   "source": [
    "# Obtén la relación filepath-docno del índice\n",
    "filepath_docno_dict = {}\n",
    "files = pt.io.find_files(\"../wiki-small\")\n",
    "indexer = pt.FilesIndexer(os.path.abspath(\"./custom_index\"), verbose=True, overwrite=True, meta={\"docno\": 20, \"filename\":512})\n",
    "indexref = indexer.index(files)\n",
    "index_tr = pt.IndexFactory.of(indexref)\n",
    "br_TF_IDF_test = pt.BatchRetrieve(index_tr, wmodel=\"TF_IDF\", metadata=[\"docno\", \"filename\"])\n",
    "\n",
    "# Obtener todos los documentos indexados\n",
    "documentos = index_tr.getCollectionStatistics().getNumberOfDocuments()\n",
    "\n",
    "# Iterar sobre los documentos indexados\n",
    "for doc_id in range(documentos):\n",
    "    docno, filepath = index_tr.getMetaIndex().getAllItems(doc_id)\n",
    "    filepath_docno_dict[filepath] = docno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf(text, stop_words_list):\n",
    "    # Calcula el term frequency (frecuencia de término)\n",
    "    tokens = tokenizer(text, stop_words_list)\n",
    "    tf = Counter(tokens)\n",
    "    return {word: count for word, count in tf.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(directory, stop_words_list):\n",
    "    # Construye el índice invertido a partir de los documentos en el directorio\n",
    "    index = {}\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            filepath = os.path.join(root, filename)\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                tf = calculate_tf(text, stop_words_list)\n",
    "                docid = filepath_docno_dict[filepath]\n",
    "                index[docid] = {'filepath': filepath, 'terms': tf}  # Agrega el docid al índice\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_idf(documents):\n",
    "    # Calcula el inverse document frequency (frecuencia inversa de documento)\n",
    "    all_words = set(word for doc in documents for word in doc.keys())\n",
    "    idf = {}\n",
    "    total_documents = len(documents)\n",
    "    for word in all_words:\n",
    "        # Calcula el número de documentos que contienen el término\n",
    "        doc_count = sum(1 for doc in documents if word in doc)\n",
    "        idf[word] = math.log(total_documents / (1 + doc_count))\n",
    "    return idf\n",
    "\n",
    "def calculate_tf_idf(tf, idf):\n",
    "    # Calcula el tf-idf para un término\n",
    "    tf_idf = {word: tf_value * idf.get(word, 0) for word, tf_value in tf.items()}\n",
    "    return tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, index, idf, stop_words_list):\n",
    "    # Busca documentos relevantes para la consulta utilizando el modelo vectorial\n",
    "    query_tf = calculate_tf(query, stop_words_list)\n",
    "    query_tf_idf = calculate_tf_idf(query_tf, idf)\n",
    "    scores = {}\n",
    "    for docid, doc_info in index.items():\n",
    "        doc_tf = doc_info['terms']\n",
    "        score = sum(query_tf_idf.get(term, 0) * doc_tf.get(term, 0) for term in query_tf_idf.keys())\n",
    "        scores[docid] = score\n",
    "    # Ordena los documentos por relevancia (puntuación)\n",
    "    ranked_documents = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Obtiene el filepath para cada docid\n",
    "    results = []\n",
    "    for docid, score in ranked_documents:\n",
    "        doc_info = index[docid]\n",
    "        filepath = doc_info['filepath']\n",
    "        results.append({'docid': docid, 'filepath': filepath, 'score': score})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construye el índice\n",
    "index = build_index(DIR, stop_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la IDF para los documentos\n",
    "idf = calculate_idf([doc_info['terms'] for doc_info in index.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta de ejemplo\n",
    "query1 = \"software\"\n",
    "query2 = \"tecnology in the high school\"\n",
    "query3 = \"ideas for design clothes\"\n",
    "query4 = \"why the sky is blue\"\n",
    "query5 = \"Alter ego of batman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca documentos relevantes para la consulta\n",
    "results_q1 = search(query1, index, idf, stop_words_list)\n",
    "results_q2 = search(query2, index, idf, stop_words_list)\n",
    "results_q3 = search(query3, index, idf, stop_words_list)\n",
    "results_q4 = search(query4, index, idf, stop_words_list)\n",
    "results_q5 = search(query5, index, idf, stop_words_list)\n",
    "\n",
    "vector_q1_My_Soft = [item['docid'] for item in results_q1]\n",
    "vector_q2_My_Soft = [item['docid'] for item in results_q2]\n",
    "vector_q3_My_Soft = [item['docid'] for item in results_q3]\n",
    "vector_q4_My_Soft = [item['docid'] for item in results_q4]\n",
    "vector_q5_My_Soft = [item['docid'] for item in results_q5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_TF_IDF = pt.BatchRetrieve(index_tr, wmodel=\"TF_IDF\", num_results=50, metadata=[\"docno\", \"filename\"])\n",
    "vector_q1_TF_IDF = br_TF_IDF.search(query1)[\"docno\"]\n",
    "vector_q2_TF_IDF = br_TF_IDF.search(query2)[\"docno\"]\n",
    "vector_q3_TF_IDF = br_TF_IDF.search(query3)[\"docno\"]\n",
    "vector_q4_TF_IDF = br_TF_IDF.search(query4)[\"docno\"]\n",
    "vector_q5_TF_IDF = br_TF_IDF.search(query5)[\"docno\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coef. Corr. q1</th>\n",
       "      <th>Coef. Corr. q2</th>\n",
       "      <th>Coef. Corr. q3</th>\n",
       "      <th>Coef. Corr. q4</th>\n",
       "      <th>Coef. Corr. q5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>@10</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.054545</td>\n",
       "      <td>0.163636</td>\n",
       "      <td>-0.284848</td>\n",
       "      <td>0.406061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@25</th>\n",
       "      <td>-0.194615</td>\n",
       "      <td>-0.051538</td>\n",
       "      <td>0.023846</td>\n",
       "      <td>-0.153077</td>\n",
       "      <td>0.196923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>@50</th>\n",
       "      <td>-0.041537</td>\n",
       "      <td>0.039520</td>\n",
       "      <td>0.263673</td>\n",
       "      <td>0.083986</td>\n",
       "      <td>0.143529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Coef. Corr. q1  Coef. Corr. q2  Coef. Corr. q3  Coef. Corr. q4  \\\n",
       "@10       -0.333333       -0.054545        0.163636       -0.284848   \n",
       "@25       -0.194615       -0.051538        0.023846       -0.153077   \n",
       "@50       -0.041537        0.039520        0.263673        0.083986   \n",
       "\n",
       "     Coef. Corr. q5  \n",
       "@10        0.406061  \n",
       "@25        0.196923  \n",
       "@50        0.143529  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_spearman10_q1, _ = scipy.stats.spearmanr(vector_q1_My_Soft[:10], vector_q1_TF_IDF[:10])\n",
    "coef_spearman25_q1, _ = scipy.stats.spearmanr(vector_q1_My_Soft[:25], vector_q1_TF_IDF[:25])\n",
    "coef_spearman50_q1, _ = scipy.stats.spearmanr(vector_q1_My_Soft[:50], vector_q1_TF_IDF[:50])\n",
    "\n",
    "coef_spearman10_q2, _ = scipy.stats.spearmanr(vector_q2_My_Soft[:10], vector_q2_TF_IDF[:10])\n",
    "coef_spearman25_q2, _ = scipy.stats.spearmanr(vector_q2_My_Soft[:25], vector_q2_TF_IDF[:25])\n",
    "coef_spearman50_q2, _ = scipy.stats.spearmanr(vector_q2_My_Soft[:50], vector_q2_TF_IDF[:50])\n",
    "\n",
    "coef_spearman10_q3, _ = scipy.stats.spearmanr(vector_q3_My_Soft[:10], vector_q3_TF_IDF[:10])\n",
    "coef_spearman25_q3, _ = scipy.stats.spearmanr(vector_q3_My_Soft[:25], vector_q3_TF_IDF[:25])\n",
    "coef_spearman50_q3, _ = scipy.stats.spearmanr(vector_q3_My_Soft[:50], vector_q3_TF_IDF[:50])\n",
    "\n",
    "coef_spearman10_q4, _ = scipy.stats.spearmanr(vector_q4_My_Soft[:10], vector_q4_TF_IDF[:10])\n",
    "coef_spearman25_q4, _ = scipy.stats.spearmanr(vector_q4_My_Soft[:25], vector_q4_TF_IDF[:25])\n",
    "coef_spearman50_q4, _ = scipy.stats.spearmanr(vector_q4_My_Soft[:50], vector_q4_TF_IDF[:50])\n",
    "\n",
    "coef_spearman10_q5, _ = scipy.stats.spearmanr(vector_q5_My_Soft[:10], vector_q5_TF_IDF[:10])\n",
    "coef_spearman25_q5, _ = scipy.stats.spearmanr(vector_q5_My_Soft[:25], vector_q5_TF_IDF[:25])\n",
    "coef_spearman50_q5, _ = scipy.stats.spearmanr(vector_q5_My_Soft[:50], vector_q5_TF_IDF[:50])\n",
    "\n",
    "dataframes = [\n",
    "    pd.DataFrame([coef_spearman10_q1, coef_spearman25_q1, coef_spearman50_q1], index=[\"@10\", \"@25\", \"@50\"], columns=[\"Coef. Corr. q1\"]),\n",
    "    pd.DataFrame([coef_spearman10_q2, coef_spearman25_q2, coef_spearman50_q2], index=[\"@10\", \"@25\", \"@50\"], columns=[\"Coef. Corr. q2\"]),\n",
    "    pd.DataFrame([coef_spearman10_q3, coef_spearman25_q3, coef_spearman50_q3], index=[\"@10\", \"@25\", \"@50\"], columns=[\"Coef. Corr. q3\"]),\n",
    "    pd.DataFrame([coef_spearman10_q4, coef_spearman25_q4, coef_spearman50_q4], index=[\"@10\", \"@25\", \"@50\"], columns=[\"Coef. Corr. q4\"]),\n",
    "    pd.DataFrame([coef_spearman10_q5, coef_spearman25_q5, coef_spearman50_q5], index=[\"@10\", \"@25\", \"@50\"], columns=[\"Coef. Corr. q5\"])\n",
    "]\n",
    "\n",
    "df_merged = pd.concat(dataframes, axis=1)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se porque da negativo, no entiendo esos numeros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
